{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae0986c",
   "metadata": {},
   "source": [
    "# 导入numpy计算库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a40bc0-aa90-41a9-9c16-4acfeba8c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfca513",
   "metadata": {},
   "source": [
    "# 任务1：实现线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b3d62",
   "metadata": {},
   "source": [
    "## 1.1 Softmax计算\n",
    "\n",
    "- 输入x：一个K维的向量\n",
    "- 输出o：一个K维的向量\n",
    "- 计算过程\n",
    "    - $o = \\exp(x)$ 这是一个向量\n",
    "    - $sum\\_o = \\text{sum}(o)$ 这是一个标量\n",
    "    - $o = \\frac{o}{sum\\_o}$\n",
    "- 使用的函数请参考文档，包括np.exp、np.sum等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37a30ba-8d2a-45fc-a385-cada130f1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # TODO: 计算输入Numpy向量x的softmax函数计算结果\n",
    "    x_max = np.max(x)\n",
    "    x = x - x_max\n",
    "    o = np.exp(x - np.max(x))\n",
    "    sum_o = np.sum(o)\n",
    "    o = o/sum_o\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c994fab",
   "metadata": {},
   "source": [
    "## 1.2 验证softmax模块\n",
    "\n",
    "输出结果大致为$[0.032,  0.087,  0.237,  0.644]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e460ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0320586  0.08714432 0.23688282 0.64391426]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "o = softmax(x)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9122e0",
   "metadata": {},
   "source": [
    "## 1.3 模型正向预测\n",
    "- 输入x：一个K维的向量\n",
    "- 输入weight：一个N * K维的矩阵\n",
    "- 输入bias：一个N维的向量\n",
    "- 输出o：一个N维的概率向量\n",
    "- 计算过程：\n",
    "    - 利用线性模型得到输出\n",
    "    - 用你实现的softmax对输出进行处理，得到概率向量\n",
    "    \n",
    "可能用到np.matmul等函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1194c55-5ed5-4789-8bac-51888bbe1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, weight, bias):\n",
    "    # TODO: 给定模型参数，计算模型预测结果o\n",
    "    f = np.matmul(weight,x) + bias\n",
    "    o = softmax(f)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e3b41",
   "metadata": {},
   "source": [
    "## 1.4 验证正向预测过程\n",
    "\n",
    "输出结果大致为[9.11e-04 9.99e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6fc403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.11051194e-04 9.99088949e-01]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([1, 2])\n",
    "x = np.array([1, 2])\n",
    "y = forward(x, w, b)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a7e0c",
   "metadata": {},
   "source": [
    "# 任务2：计算损失函数\n",
    "- 输入y：一个整数，表示真实标签\n",
    "- 输入o：一个N维向量，表示模型的预测概率（已经经过softmax处理了的模型输出结果）\n",
    "- 输出loss：一个实数，表示损失函数的计算结果\n",
    "\n",
    "这里可能用到np.log等函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de075af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y, o):\n",
    "    label_num = o.shape[0]\n",
    "    y_onehot = np.zeros(label_num)\n",
    "    \n",
    "    # TODO: 把y转换到y_onehot上，然后计算交叉熵loss\n",
    "    y_onehot[y] = 1\n",
    "    loss = np.sum(-np.matmul(y_onehot,np.log(o)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217daece",
   "metadata": {},
   "source": [
    "## 验证损失函数计算\n",
    "输出结果大致为0.6931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e710402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "y = 0\n",
    "o = np.array([0.5, 0.25, 0.25])\n",
    "print(cross_entropy_loss(y, o))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82142e19",
   "metadata": {},
   "source": [
    "# 任务3：实现梯度计算过程\n",
    "\n",
    "- 输入x：一个K维的向量\n",
    "- 输入o：一个N维的向量\n",
    "- 输入y：一个整数的标签\n",
    "- 输入weight：一个N * K维的矩阵\n",
    "- 输入bias：一个N维的向量\n",
    "- 输出weight_grad：一个N * K维的矩阵，是由loss计算到的weight的梯度\n",
    "- 输出bias_grad：一个N维的向量，是由loss计算到的bias的梯度\n",
    "\n",
    "这里可能会用到np.outer函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af72f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x, o, y, weight, bias):\n",
    "    label_num = o.shape[0]\n",
    "    y_onehot = np.zeros(label_num)\n",
    "    \n",
    "    # TODO: 把y转换到y_onehot上，然后计算模型参数的梯度\n",
    "    y_onehot[y] = 1   \n",
    "    f = forward(x, weight, bias)\n",
    "    weight_grad = - np.outer(y_onehot - f,x)\n",
    "    bias_grad = - (y_onehot - f)\n",
    "    return weight_grad, bias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21702b09",
   "metadata": {},
   "source": [
    "## 验证梯度计算公式\n",
    "\n",
    "输出结果大致为(array([[ 0.00091105,  0.0018221 ],\n",
    "       [-0.00091105, -0.0018221 ]]), array([ 0.00091105, -0.00091105]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a5b6a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.00091105,  0.0018221 ],\n",
      "       [-0.00091105, -0.0018221 ]]), array([ 0.00091105, -0.00091105]))\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([1, 2])\n",
    "x = np.array([1, 2])\n",
    "y = 1\n",
    "o = forward(x, w, b)\n",
    "print(backward(x, o, y, w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ff4de",
   "metadata": {},
   "source": [
    "# 任务4：模型训练\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca130e",
   "metadata": {},
   "source": [
    "## 准备步骤\n",
    "\n",
    "加载数据，初始化模型参数，定义关键变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdac14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_num = 3\n",
    "input_size = 13\n",
    "\n",
    "# epoches = 1000\n",
    "epoches = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "trainset = np.load(\"trainset.npy\", allow_pickle=True)\n",
    "testset = np.load(\"testset.npy\", allow_pickle=True)\n",
    "\n",
    "weight = np.random.uniform(-0.1, 0.1, (label_num, input_size))\n",
    "bias = np.random.uniform(-0.1, 0.1, label_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e350d",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "如果上述三个模块实现正确，loss将越来越小、逐渐收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1135fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1, averaged loss=1.115\n",
      "epoch=2, averaged loss=14.940\n",
      "epoch=3, averaged loss=140.572\n",
      "epoch=4, averaged loss=184.728\n",
      "epoch=5, averaged loss=74.109\n",
      "epoch=6, averaged loss=165.228\n",
      "epoch=7, averaged loss=24.811\n",
      "epoch=8, averaged loss=24.039\n",
      "epoch=9, averaged loss=49.186\n",
      "epoch=10, averaged loss=50.616\n",
      "epoch=11, averaged loss=16.507\n",
      "epoch=12, averaged loss=40.704\n",
      "epoch=13, averaged loss=19.816\n",
      "epoch=14, averaged loss=32.606\n",
      "epoch=15, averaged loss=10.149\n",
      "epoch=16, averaged loss=7.238\n",
      "epoch=17, averaged loss=1.616\n",
      "epoch=18, averaged loss=0.547\n",
      "epoch=19, averaged loss=0.426\n",
      "epoch=20, averaged loss=0.385\n",
      "epoch=21, averaged loss=0.356\n",
      "epoch=22, averaged loss=0.328\n",
      "epoch=23, averaged loss=0.458\n",
      "epoch=24, averaged loss=0.415\n",
      "epoch=25, averaged loss=0.418\n",
      "epoch=26, averaged loss=0.306\n",
      "epoch=27, averaged loss=0.293\n",
      "epoch=28, averaged loss=0.227\n",
      "epoch=29, averaged loss=0.179\n",
      "epoch=30, averaged loss=0.186\n",
      "epoch=31, averaged loss=0.335\n",
      "epoch=32, averaged loss=0.460\n",
      "epoch=33, averaged loss=0.206\n",
      "epoch=34, averaged loss=0.174\n",
      "epoch=35, averaged loss=0.175\n",
      "epoch=36, averaged loss=0.175\n",
      "epoch=37, averaged loss=0.224\n",
      "epoch=38, averaged loss=0.165\n",
      "epoch=39, averaged loss=0.133\n",
      "epoch=40, averaged loss=0.100\n",
      "epoch=41, averaged loss=0.104\n",
      "epoch=42, averaged loss=0.167\n",
      "epoch=43, averaged loss=0.317\n",
      "epoch=44, averaged loss=0.132\n",
      "epoch=45, averaged loss=0.075\n",
      "epoch=46, averaged loss=0.066\n",
      "epoch=47, averaged loss=0.069\n",
      "epoch=48, averaged loss=0.104\n",
      "epoch=49, averaged loss=0.127\n",
      "epoch=50, averaged loss=0.254\n",
      "epoch=51, averaged loss=0.109\n",
      "epoch=52, averaged loss=0.047\n",
      "epoch=53, averaged loss=0.028\n",
      "epoch=54, averaged loss=0.023\n",
      "epoch=55, averaged loss=0.024\n",
      "epoch=56, averaged loss=0.055\n",
      "epoch=57, averaged loss=0.140\n",
      "epoch=58, averaged loss=0.044\n",
      "epoch=59, averaged loss=0.060\n",
      "epoch=60, averaged loss=0.020\n",
      "epoch=61, averaged loss=0.065\n",
      "epoch=62, averaged loss=0.037\n",
      "epoch=63, averaged loss=0.086\n",
      "epoch=64, averaged loss=0.031\n",
      "epoch=65, averaged loss=0.069\n",
      "epoch=66, averaged loss=0.019\n",
      "epoch=67, averaged loss=0.052\n",
      "epoch=68, averaged loss=0.019\n",
      "epoch=69, averaged loss=0.056\n",
      "epoch=70, averaged loss=0.014\n",
      "epoch=71, averaged loss=0.038\n",
      "epoch=72, averaged loss=0.015\n",
      "epoch=73, averaged loss=0.039\n",
      "epoch=74, averaged loss=0.010\n",
      "epoch=75, averaged loss=0.021\n",
      "epoch=76, averaged loss=0.015\n",
      "epoch=77, averaged loss=0.036\n",
      "epoch=78, averaged loss=0.008\n",
      "epoch=79, averaged loss=0.009\n",
      "epoch=80, averaged loss=0.006\n",
      "epoch=81, averaged loss=0.002\n",
      "epoch=82, averaged loss=0.001\n",
      "epoch=83, averaged loss=0.001\n",
      "epoch=84, averaged loss=0.001\n",
      "epoch=85, averaged loss=0.001\n",
      "epoch=86, averaged loss=0.001\n",
      "epoch=87, averaged loss=0.001\n",
      "epoch=88, averaged loss=0.001\n",
      "epoch=89, averaged loss=0.001\n",
      "epoch=90, averaged loss=0.001\n",
      "epoch=91, averaged loss=0.001\n",
      "epoch=92, averaged loss=0.001\n",
      "epoch=93, averaged loss=0.001\n",
      "epoch=94, averaged loss=0.001\n",
      "epoch=95, averaged loss=0.001\n",
      "epoch=96, averaged loss=0.001\n",
      "epoch=97, averaged loss=0.001\n",
      "epoch=98, averaged loss=0.001\n",
      "epoch=99, averaged loss=0.001\n",
      "epoch=100, averaged loss=0.001\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epoches+1):\n",
    "    \n",
    "    total_loss = total_weight_grad = total_bias_grad = 0\n",
    "    count = 0\n",
    "    \n",
    "    for x, y in trainset:\n",
    "        \n",
    "        # TODO: 得到模型预测结果o\n",
    "        o = forward(x,weight,bias)\n",
    "        \n",
    "        # TODO: 计算损失函数loss\n",
    "        loss = cross_entropy_loss(y, o)\n",
    "        \n",
    "        # TODO: 计算梯度\n",
    "        weight_grad, bias_grad = backward(x, o, y, weight, bias)\n",
    "        \n",
    "        count += 1\n",
    "        total_loss += loss\n",
    "        total_weight_grad += weight_grad\n",
    "        total_bias_grad += bias_grad\n",
    "    \n",
    "    # TODO：实现SGD公式\n",
    "    weight = weight - total_weight_grad\n",
    "    bias = bias - total_bias_grad\n",
    "    \n",
    "    avg_loss = total_loss / count\n",
    "    print('epoch=%d, averaged loss=%.3f' % (epoch, avg_loss))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73ca77",
   "metadata": {},
   "source": [
    "# 任务5：验证模型准确度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73364673",
   "metadata": {},
   "source": [
    "## 实现准确度计算模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ff5b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(weight, bias, dataset):\n",
    "    # 返回模型在数据集上的预测准确率\n",
    "    \n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for x, y in dataset:\n",
    "        \n",
    "        # TODO：获取模型预测结果\n",
    "        o = forward(x,weight,bias)\n",
    "        # print(o)\n",
    "        # print(y)\n",
    "        # TODO: 取出模型置信度最大是哪个维度\n",
    "        maxdim = np.argmax(o)\n",
    "        # TODO：比较模型预测结果，计算correct（正确计数）和count（总量计数）\n",
    "        if y == maxdim:\n",
    "            correct += 1\n",
    "        count += 1\n",
    "\n",
    "    acc = correct / count\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520720c5",
   "metadata": {},
   "source": [
    "## 计算准确度 \n",
    "计算并输出模型在trainset和test上的预测准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6649540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: 统计训练集和测试集上的准确率\n",
    "train_acc = calc_accuracy(weight, bias, trainset)\n",
    "test_acc = calc_accuracy(weight, bias, testset)\n",
    "\n",
    "print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b650d5-759f-437f-a9a9-07ddf112e318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
