{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement LeNet-5\n",
    "\n",
    "- 在Week3的实验中，你已经学会了如何使用PyTorch内部封装好的模块，实现一个多层MLP模型。\n",
    "\n",
    "- 在本周的实验任务Task1中，我们将：\n",
    "  1. 继续利用PyTorch的内置神经网络模块（torch.nn.Module的子类）实现一个卷积神经网络LeNet5；\n",
    "  2. 在实现好的LeNet5模型上，利用PyTorch的内置优化器实现模型的训练；\n",
    "  3. 评估训好的模型的预测性能，并将其保存、以便本周任务Task2的调用。\n",
    "\n",
    "- 具体实验步骤如下：\n",
    "  1. 将代码文件（Python文件与Notebook文件）上传到服务器端根目录；\n",
    "  2. 依照提示，完成Python文件中的TODO内容：\n",
    "     - 一个LeNet5模型结构的定义\n",
    "     - 该模型的前向传播的实现\n",
    "  3. 执行代码完成模型训练、测试和保存。\n",
    "     - **正确实现，测试的accuracy应该高于93%**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数定义、数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Week567_General_Code_Question import LeNet5, load_mnist\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "epoch = 10\n",
    "train_loader, test_loader = load_mnist(batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的准备\n",
    "\n",
    "请你在文件Week567_General_Code_Question.py的LeNet5类中实现两个TODO内容：\n",
    "- 一个LeNet5模型结构的定义\n",
    "- 该模型的前向传播的实现\n",
    "\n",
    "下面是一些供你参考/可能用到的API函数：\n",
    "\n",
    "- torch.nn.Conv2d(*in_channels*, *out_channels*, *kernel_size*, *stride=1*, *padding=0*, *bias=True*) [link](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "  - in_channels: 输入网络层的通道数\n",
    "  - out_channels: 输出网络层的通道数\n",
    "  - kernel_size: 卷积核的边长\n",
    "  - stride: 卷积操作（滑动窗口）的步长\n",
    "  - padding: 输入两端补零的数目\n",
    "- torch.nn.MaxPool2d(*kernel_size*) [link](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n",
    "  - kernel_size: 池化操作的窗口边长\n",
    "- torch.nn.Linear(*in_features*, *out_features*, *bias=True*) [\n",
    "  Link](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "  - in_features: 输入网络层的特征维度\n",
    "  - out_features: 输出网络层的特征维度\n",
    "- torch.nn.ReLU() [Link](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
    "  - 常用的激活函数\n",
    "- torch.Tensor.reshape(*shape*) [Link](https://pytorch.org/docs/stable/generated/torch.Tensor.reshape.html)\n",
    "  - shape: 当前tensor希望修改为的形状，如(2, 2)或(-1, 3)\n",
    "    - -1指该维度大小根据原数据维度大小和其它给定维度大小计算得到，至多可以给一个-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数、优化算法\n",
    "\n",
    "我们仍然使用上周的CrossEntropyLoss，以及SGD优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:20<00:00, 22.99it/s, epoch=0, train_loss=0.349]\n",
      "100%|██████████| 469/469 [00:19<00:00, 23.86it/s, epoch=1, train_loss=0.126] \n",
      "100%|██████████| 469/469 [00:19<00:00, 24.18it/s, epoch=2, train_loss=0.18]  \n",
      "100%|██████████| 469/469 [00:19<00:00, 24.06it/s, epoch=3, train_loss=0.132] \n",
      "100%|██████████| 469/469 [00:19<00:00, 23.85it/s, epoch=4, train_loss=0.0711]\n",
      "100%|██████████| 469/469 [00:19<00:00, 24.02it/s, epoch=5, train_loss=0.0509]\n",
      "100%|██████████| 469/469 [00:19<00:00, 23.73it/s, epoch=6, train_loss=0.0217]\n",
      "100%|██████████| 469/469 [00:20<00:00, 22.89it/s, epoch=7, train_loss=0.0183]\n",
      "100%|██████████| 469/469 [00:19<00:00, 23.65it/s, epoch=8, train_loss=0.0477]\n",
      "100%|██████████| 469/469 [00:20<00:00, 22.94it/s, epoch=9, train_loss=0.0339]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for e in range(epoch):\n",
    "    t = tqdm(train_loader)\n",
    "    for img, label in t:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img)\n",
    "        loss = criterion(pred, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        t.set_postfix(epoch=e, train_loss=loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的测试\n",
    "\n",
    "- torch.argmax(*input*, *dim*, *keepdim=False*) [Link](https://pytorch.org/docs/stable/generated/torch.argmax.html)\n",
    "  - input: 计算基于的tensor\n",
    "  - dim: 希望按哪个维度求max下标\n",
    "\n",
    "**如果LeNet5实现正确，测试的accuracy应该高于93%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 101.50it/s, test_acc=0.988]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct_cnt, sample_cnt = 0, 0\n",
    "\n",
    "t = tqdm(test_loader)\n",
    "for img, label in t:\n",
    "    pred = model(img)\n",
    "    pred_label = pred.argmax(dim=1)\n",
    "    \n",
    "    correct_cnt += (pred_label == label).sum().item()\n",
    "    sample_cnt += pred_label.shape[0]\n",
    "\n",
    "    t.set_postfix(test_acc=correct_cnt/sample_cnt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的保存\n",
    "\n",
    "我们将完成训练的模型保存到服务器的model/目录下，方便Task2的使用。\n",
    "\n",
    "ModelScope服务器端无法长久保存文件，因此**请及时下载、本地保存你完成的代码，以及模型的参数文件（model/plt.pt）**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('model/'):\n",
    "    os.mkdir('model/')\n",
    "\n",
    "torch.save(model.state_dict(), 'model/lenet5.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
